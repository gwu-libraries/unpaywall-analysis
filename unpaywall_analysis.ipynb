{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of OA-availability of subscribed journals\n",
    "December 2020\n",
    "\n",
    "#### Dataset components\n",
    "1. Unpaywall [database snapshot](https://unpaywall.org/products/snapshot), updated on 10-09-2020; accessed 11-25-2020. \n",
    "2. [ISSN-L](https://www.issn.org/understanding-the-issn/assignment-rules/the-issn-l-for-publications-on-multiple-media/) mapping table, accessed on 11-23-2020.\n",
    "3. GW Elsevier/ScienceDirect subscribed journals (FY 2020) as of 12-01-2020.\n",
    "\n",
    "#### Methodology\n",
    "1. Reduce the Unpaywall database to the following fields:\n",
    "   - `journal_issn_l`  (for linking on library subscriptions)\n",
    "   - `doi` (unique article identifier) \n",
    "   - `year` (of publication) \n",
    "   - `is_oa` (is this article available OA?)\n",
    "2. Match library journal titles to their ISSN-L.\n",
    "3. Match the latter to the corresponding rows in the Unpaywall database.\n",
    "4. Compute metrics per title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unpaywall database is a single JSON-L (line-break-delimited JSON) file. The current snapshot is approximately 175 GB, so far too large to load in memory.\n",
    "\n",
    "But we can use `json.loads` to inspect a single row to determine the fields we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./unpaywall_snapshot_2020-10-09T153852.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(next(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the [Dask distributed](https://distributed.dask.org/en/latest/) module to process the Unpaywall JSON in parallel without persisting it in memory.\n",
    "\n",
    "The `client` allows us to monitor performance as well as use distributed processing by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55681</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55681' processes=4 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple function will extract the fields we want from the JSON data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(record):\n",
    "    return {'issn_l': record.get('journal_issn_l'),\n",
    "           'doi': record.get('doi'),\n",
    "           'year': record.get('year'),\n",
    "           'is_oa': record.get('is_oa'),\n",
    "           'genre': record.get('genre'),\n",
    "           'is_paratext': record.get('is_paratext')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask pipeline: data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the JSON file as text and map it to `json.loads`. (We don't need to use `jsonlines` because the Dask worker will automatically read the file line by line.\n",
    "\n",
    "**Note**: Setting the `blocksize` parameter is important: without it, dask allocates the whole file to a single worker, which defeats the parallelization (and on my machine, caused the task to restart before finishing every time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = db.read_text('./unpaywall_snapshot_2020-10-09T153852.jsonl', blocksize='128MiB').map(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Map the custom function to the JSON and then convert to a DataFrame, setting the `dtype` for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.map(flatten).to_dataframe(meta={'issn_l': 'object',\n",
    "                                      'doi': 'object',\n",
    "                                      'year': 'object',\n",
    "                                      'is_oa': 'object',\n",
    "                                      'genre': 'object',\n",
    "                                      'is_paratext': 'object'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Save the DataFrame to disk as parquet files. (The conversion from `object` to `str` seems to be necessary for `pyarrow`, at least. Try next time with `fastparquet`?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_parquet('./unpaywall_parquet', engine='fastparquet')\n",
    "df.astype(str).to_parquet('./unpaywall_parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restart the notebook kernel here.** (We're using a differently configured dask client for subsequent operations, so it's easiest just to start with a new kernel at this point.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping the local subscription data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read a CSV of journals we subscribe to. (These are from a report run in Alma Analytics.) \n",
    "   - Each journal occupies a single line. \n",
    "   - ISSN's are included for matching.\n",
    "   - We also include the Alma unique title identifier (MMS Id). (This number is unique per title, whereas a single title may have multiple ISSN's.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_jrnls = pd.read_csv('./elsevier-subs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_jrnls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Exclude those rows where the ISSN field is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_jrnls = elsevier_jrnls.loc[~elsevier_jrnls.ISSN.isnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reindex the DataFrame on the unique identifier (this will make reshaping it easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_jrnls = elsevier_jrnls.set_index('MMS Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split the semicolon-delimited ISSN field into multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_issns = elsevier_jrnls.ISSN.str.split('; ', expand=True)\\\n",
    "                        .rename(columns={n: f'issn{n}' for n in range(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issn0</th>\n",
       "      <th>issn1</th>\n",
       "      <th>issn2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMS Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9927679463604107</th>\n",
       "      <td>0360-8557</td>\n",
       "      <td>0742-1974</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185880941204107</th>\n",
       "      <td>0740-624X</td>\n",
       "      <td>0740-624X</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185890753304107</th>\n",
       "      <td>0747-5632</td>\n",
       "      <td>0747-5632</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969962313604107</th>\n",
       "      <td>0953-9611</td>\n",
       "      <td>0954-0504</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185890742504107</th>\n",
       "      <td>1090-2147</td>\n",
       "      <td>0278-2626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       issn0      issn1 issn2\n",
       "MMS Id                                       \n",
       "9927679463604107   0360-8557  0742-1974  None\n",
       "99185880941204107  0740-624X  0740-624X  None\n",
       "99185890753304107  0747-5632  0747-5632  None\n",
       "9969962313604107   0953-9611  0954-0504  None\n",
       "99185890742504107  1090-2147  0278-2626  None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_issns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Load the ISSN-to-ISSN-L mapping table from the ISSN authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('issnltables/20201123.ISSN-to-ISSN-L.txt', 'r') as f:\n",
    "    issn_tbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Convert this tab-delimited table to a dictionary. Keys are ISSN's; values are ISSN-L's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "issn_tbl=issn_tbl.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last row is a null\n",
    "issn_tbl = dict(((l.split('\\t') for l in issn_tbl[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Reshape our DataFrame of ISSN's into a Series where each row consists of a single ISSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-23d9f5ba53a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melsevier_issns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melsevier_issns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'stack'"
     ]
    }
   ],
   "source": [
    "elsevier_issns = elsevier_issns.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Here we add a second column to our Series (creating a DataFrame) that maps every ISSN from our list of subscriptions to a its ISSN-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_issns = pd.concat([elsevier_issns, elsevier_issns.apply(lambda x: issn_tbl.get(x))], axis=1)\\\n",
    "                                        .rename(columns={0: 'issn_alma', 1: 'issn_l'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of any duplicates\n",
    "elsevier_issns = elsevier_issns.reset_index().drop_duplicates(subset='issn_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMS Id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>issn_alma</th>\n",
       "      <th>issn_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9927679463604107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>0360-8557</td>\n",
       "      <td>0360-8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9927679463604107</td>\n",
       "      <td>issn1</td>\n",
       "      <td>0742-1974</td>\n",
       "      <td>0742-1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99185880941204107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>0740-624X</td>\n",
       "      <td>0740-624X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99185890753304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>0747-5632</td>\n",
       "      <td>0747-5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9969962313604107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>0953-9611</td>\n",
       "      <td>0953-9611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MMS Id level_1  issn_alma     issn_l\n",
       "0   9927679463604107   issn0  0360-8557  0360-8557\n",
       "1   9927679463604107   issn1  0742-1974  0742-1974\n",
       "2  99185880941204107   issn0  0740-624X  0740-624X\n",
       "4  99185890753304107   issn0  0747-5632  0747-5632\n",
       "6   9969962313604107   issn0  0953-9611  0953-9611"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_issns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask pipeline: Analysis\n",
    "\n",
    "The objective here is to merge our small DataFrame of subscriptions with the Unpaywall database in order to retrieve OA-information about the contents of each journal over time. Since the Unpaywall database, even in its reduced form, does not fit into memory, we're again using dask to handle this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Restart the dask client. Here we set the `processes` parameter to false to use a single worker. (On my machine, distributed processing did not work for merging, though I'm not sure why. It is a [documented use case](https://docs.dask.org/en/latest/dataframe-joins.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.0.19/40324/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.0.19:8787/status' target='_blank'>http://192.168.0.19:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.0.19/40324/1' processes=1 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a dask `DataFrame` from the parquet files saved above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.dataframe.read_parquet('./unpaywall_parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. This is the computationally intensive part. On my MacBook Pro 2019 (2.8 GHz Intel Core i7), it took about 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged = dask.dataframe.merge(df, elsevier_issns, how='right', on='issn_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - WARNING - gc.collect() took 1.125s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n"
     ]
    }
   ],
   "source": [
    "elsevier_merged = elsevier_merged.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issn_l</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>is_oa</th>\n",
       "      <th>genre</th>\n",
       "      <th>is_paratext</th>\n",
       "      <th>MMS Id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>issn_alma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0022-0965</td>\n",
       "      <td>10.1016/j.jecp.2019.104675</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>False</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>99185890742304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>1096-0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022-0965</td>\n",
       "      <td>10.1016/0022-0965(76)90079-5</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>False</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>99185890742304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>1096-0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0022-0965</td>\n",
       "      <td>10.1016/j.jecp.2020.104944</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>False</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>99185890742304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>1096-0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0022-0965</td>\n",
       "      <td>10.1016/0022-0965(88)90060-4</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>False</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>99185890742304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>1096-0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0022-0965</td>\n",
       "      <td>10.1016/j.jecp.2019.104708</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>True</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>99185890742304107</td>\n",
       "      <td>issn0</td>\n",
       "      <td>1096-0457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      issn_l                           doi    year  is_oa            genre  \\\n",
       "0  0022-0965    10.1016/j.jecp.2019.104675  2019.0  False  journal-article   \n",
       "1  0022-0965  10.1016/0022-0965(76)90079-5  1976.0  False  journal-article   \n",
       "2  0022-0965    10.1016/j.jecp.2020.104944  2020.0  False  journal-article   \n",
       "3  0022-0965  10.1016/0022-0965(88)90060-4  1988.0  False  journal-article   \n",
       "4  0022-0965    10.1016/j.jecp.2019.104708  2020.0   True  journal-article   \n",
       "\n",
       "  is_paratext             MMS Id level_1  issn_alma  \n",
       "0       False  99185890742304107   issn0  1096-0457  \n",
       "1       False  99185890742304107   issn0  1096-0457  \n",
       "2       False  99185890742304107   issn0  1096-0457  \n",
       "3       False  99185890742304107   issn0  1096-0457  \n",
       "4       False  99185890742304107   issn0  1096-0457  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged.to_csv('./elsevier_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 137 unique ISSN's, we retrieved 560K DOI's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issn_l            137\n",
       "doi            561009\n",
       "year               66\n",
       "is_oa               2\n",
       "genre               3\n",
       "is_paratext         2\n",
       "MMS Id            135\n",
       "level_1             2\n",
       "issn_alma         138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elsevier_merged.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Clean up the merged dataset.\n",
    "   - Drop rows where the publication year is null. \n",
    "   - Drop the ISSN columns; we have those in our original dataset, to which we can match using the unique title ID's.\n",
    "   - Convert data types from string to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged = elsevier_merged.loc[~elsevier_merged.year.isnull() & (elsevier_merged.year != 'nan')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged = elsevier_merged.drop(['level_1', 'issn_alma'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged.is_oa = elsevier_merged.is_oa.apply(lambda x: True if x == 'True' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged.is_paratext = elsevier_merged.is_paratext.apply(lambda x: True if x == 'True' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged.year = elsevier_merged.year.astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. As a validation step/sanity check, I created a random sample of DOI's from our merged dataset to check against results from the [Unpaywall Simple Query Tool](https://unpaywall.org/products/simple-query-tool). (You can paste in up to 1,000 DOI's and receive the Unpaywall data for those as a CSV.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_merged.sample(999).doi.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./unpaywall_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample[['doi', 'is_oa']].merge(elsevier_merged, suffixes=['_sample', '_actual'], on='doi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unpaywall snapshot we're using here is a couple of months old. So the 0.6% mismatch rate probably reflects DOI's whose status has changed since the snapshot was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.loc[result.is_oa_sample != result.is_oa_actual]) / len(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the `genre` and `is_paratext` fields to exclude DOI's for non-journal articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_merged = elsevier_merged.loc[(elsevier_merged.genre == 'journal-article') \\\n",
    "                                      & elsevier_merged.is_paratext].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculate the number of DOI's per title per year in each OA category (_i.e._, where `is_oa` is `True` or `False`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_counts = elsevier_merged.groupby(['MMS Id', 'year', 'is_oa']).doi.count().unstack(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Merge with the original subscriptions dataset to include the full title information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_oa = oa_counts.reset_index().merge(elsevier_jrnls, on='MMS Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our unique title ID's to strings so that when reading from CSV later, \n",
    "# they won't get put into scientific notation by helpful algorithms in Excel, etc.\n",
    "elsevier_oa['MMS Id'] = elsevier_oa['MMS Id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Convert the raw counts from `is_oa` to a total number of DOI's and a percentage for which `is_oa` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_oa[False] = elsevier_oa[False].fillna(0)\n",
    "elsevier_oa[True] = elsevier_oa[True].fillna(0)\n",
    "elsevier_oa['Total Articles'] = elsevier_oa[False] + elsevier_oa[True]\n",
    "elsevier_oa['Percent OA'] = elsevier_oa[True] / elsevier_oa['Total Articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_oa = elsevier_oa.drop([True, False], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_oa.to_csv('elsevier_oa_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. To create a more readable and manageable subset, I did the following:\n",
    "   - Limit to those rows where the publication year is 2015 or later.\n",
    "   - Pivot the years from rows to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [c for c in elsevier_oa.columns if c not in ['Total Articles', 'Percent OA']]\n",
    "elsevier_metrics = elsevier_oa.loc[elsevier_oa.year >= 2015]\\\n",
    "                        .groupby(group_cols).agg({'Percent OA': 'sum',\n",
    "                                          'Total Articles': 'sum'}) \\\n",
    "                        .unstack(level=1)\\\n",
    "                        .stack(level=0)\\\n",
    "                        .sort_index(level=[3,5], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elsevier_metrics.to_csv('elsevier_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
